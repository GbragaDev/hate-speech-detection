{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5828a3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.986629,
     "end_time": "2024-05-06T20:12:14.700528",
     "exception": false,
     "start_time": "2024-05-06T20:12:13.713899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac216b34",
   "metadata": {
    "papermill": {
     "duration": 0.006754,
     "end_time": "2024-05-06T20:12:14.715004",
     "exception": false,
     "start_time": "2024-05-06T20:12:14.708250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introdução\n",
    "\n",
    "\n",
    "[](http://)Projeto: Hate Speech Detector\n",
    "\n",
    "# Descrição\n",
    "\n",
    ">Este projeto desenvolve um modelo de machine learning utilizando processamento de linguagem natural (NLP) para detectar discursos de ódio em tweets. O código inclui etapas de importação de bibliotecas, pré-processamento de texto, vetorização, modelagem, avaliação e visualização dos resultados.\n",
    "\n",
    "\n",
    "\n",
    "# Tecnologias Utilizadas\n",
    "\n",
    "* Python 3.8+\n",
    "* Pandas\n",
    "* NumPy\n",
    "* scikit-learn\n",
    "* NLTK\n",
    "* TensorFlow\n",
    "* Matplotlib\n",
    "\n",
    "\n",
    "# Estrutura do Código\n",
    "\n",
    "1. Importação de Bibliotecas: Carregamento de todas as bibliotecas necessárias para o projeto.\n",
    "\n",
    "2. Funções de Auxílio: Funções para limpeza de texto, visualização de dados processados, e plotagem de curvas de aprendizado e matrizes de confusão.\n",
    "\n",
    "3. Carregamento dos Dados: Carrega e pré-processa o dataset de tweets.\n",
    "\n",
    "4. Exploração de Dados: Visualização inicial dos dados para entender a estrutura e as características principais.\n",
    "\n",
    "5. Pré-processamento de Dados: Limpeza e tokenização do texto dos tweets.\n",
    "\n",
    "6. Vetorização dos Dados: Conversão dos dados textuais em uma representação numérica usando TF-IDF.\n",
    "\n",
    "7. Modelagem: Construção e treinamento do modelo de rede neural.\n",
    "\n",
    "8. Avaliação do Modelo: Avaliação da precisão do modelo e apresentação de relatórios de classificação.\n",
    "\n",
    "9. Visualizações de Resultados: Gráficos para visualizar a precisão do modelo ao longo das épocas e a matriz de confusão.\n",
    "\n",
    "10. Conclusões: Sumário sobre a eficácia do modelo e suas aplicações.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622b40db",
   "metadata": {
    "papermill": {
     "duration": 0.007005,
     "end_time": "2024-05-06T20:12:14.729303",
     "exception": false,
     "start_time": "2024-05-06T20:12:14.722298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Importação de Bibliotecas\n",
    "> Nesta célula, importamos todas as bibliotecas necessárias para o projeto. Isso inclui bibliotecas para manipulação de dados (`pandas`, `numpy`), processamento de texto (`nltk`, `re`), modelagem (`tensorflow`, `sklearn`) e visualização (`matplotlib`). A importação de todas as bibliotecas no início ajuda a manter o notebook organizado e assegura que todas as dependências estão atendidas antes de executar as células subsequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c584c25b",
   "metadata": {
    "papermill": {
     "duration": 35.939631,
     "end_time": "2024-05-06T20:12:50.675816",
     "exception": false,
     "start_time": "2024-05-06T20:12:14.736185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score, confusion_matrix\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# 1. Importação de Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31787a9",
   "metadata": {
    "papermill": {
     "duration": 0.006619,
     "end_time": "2024-05-06T20:12:50.689732",
     "exception": false,
     "start_time": "2024-05-06T20:12:50.683113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## 2. Carregamento dos Dados\n",
    "> \n",
    "> Carregamos o dataset `labeled_data.csv` usando `pandas`. Esta célula inclui também a remoção de colunas desnecessárias como `'Unnamed: 0'`, que geralmente são índices residuais de operações anteriores de salvamento de dados. Isso simplifica o DataFrame, mantendo apenas as colunas relevantes para a análise.\n",
    "> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6707df1",
   "metadata": {
    "papermill": {
     "duration": 0.129122,
     "end_time": "2024-05-06T20:12:50.825798",
     "exception": false,
     "start_time": "2024-05-06T20:12:50.696676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Carregamento dos Dados\n",
    "df = pd.read_csv('../input/hate-speech-and-offensive-language-dataset/labeled_data.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)  # Removendo a coluna desnecessária"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de4798",
   "metadata": {
    "papermill": {
     "duration": 0.006717,
     "end_time": "2024-05-06T20:12:50.841008",
     "exception": false,
     "start_time": "2024-05-06T20:12:50.834291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Funções de Auxílio\n",
    "> Definimos várias funções úteis que serão utilizadas ao longo do notebook para limpar e processar os dados, mostrar dados processados, plotar a curva de aprendizado e a matriz de confusão. Estas funções ajudam a evitar a repetição de código e tornam o processo mais modular e claro.\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d87acb",
   "metadata": {
    "papermill": {
     "duration": 0.017686,
     "end_time": "2024-05-06T20:12:50.865652",
     "exception": false,
     "start_time": "2024-05-06T20:12:50.847966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Funções de Auxílio\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove URLs, tags HTML e caracteres especiais e converte para minúsculas.\"\"\"\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0776b5",
   "metadata": {
    "papermill": {
     "duration": 0.017725,
     "end_time": "2024-05-06T20:12:50.890984",
     "exception": false,
     "start_time": "2024-05-06T20:12:50.873259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(history):\n",
    "    \"\"\"Plota a curva de aprendizado com base no histórico de treinamento.\"\"\"\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history['accuracy'], label='Accuracy (training data)')\n",
    "    plt.plot(history.history['val_accuracy'], label='Accuracy (validation data)')\n",
    "    plt.title('Model Accuracy Over Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d458ad4",
   "metadata": {
    "papermill": {
     "duration": 0.015783,
     "end_time": "2024-05-06T20:12:50.913800",
     "exception": false,
     "start_time": "2024-05-06T20:12:50.898017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_classification_report(y_true, y_pred):\n",
    "    \"\"\"Plota o relatório de classificação como um gráfico de matriz de confusão.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d5c94c",
   "metadata": {
    "papermill": {
     "duration": 0.01611,
     "end_time": "2024-05-06T20:12:50.937035",
     "exception": false,
     "start_time": "2024-05-06T20:12:50.920925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_processed_data(df, num_samples=5):\n",
    "    \"\"\"Exibe uma amostra dos dados após o pré-processamento.\"\"\"\n",
    "    print(df[['clean_text', 'tokens']].sample(num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ec00c",
   "metadata": {
    "papermill": {
     "duration": 0.006705,
     "end_time": "2024-05-06T20:12:50.950692",
     "exception": false,
     "start_time": "2024-05-06T20:12:50.943987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Exploração de Dados\n",
    "> Nesta parte, exploramos os dados para obter um entendimento básico de suas características e estrutura. Usamos métodos como `.head()` para ver as primeiras entradas e `.describe()` para obter um resumo estatístico das colunas numéricas. Isso é crucial para identificar problemas iniciais de dados, como valores ausentes ou distribuições estranhas que podem necessitar de limpeza adicional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee9a01",
   "metadata": {
    "papermill": {
     "duration": 0.043344,
     "end_time": "2024-05-06T20:12:51.001113",
     "exception": false,
     "start_time": "2024-05-06T20:12:50.957769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Exploração de Dados\n",
    "# [Code cell]\n",
    "print(df.head())\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f178a43",
   "metadata": {
    "papermill": {
     "duration": 0.007087,
     "end_time": "2024-05-06T20:12:51.015660",
     "exception": false,
     "start_time": "2024-05-06T20:12:51.008573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Estrutura do DataFrame:\n",
    "\n",
    "A primeira tabela mostra um exemplo das primeiras cinco linhas do DataFrame, incluindo as seguintes colunas:\n",
    "\n",
    "count: Número de pessoas que rotularam o tweet.\n",
    "\n",
    "hate_speech: Número de rotuladores que classificaram o tweet como discurso de ódio.\n",
    "\n",
    "offensive_language: Número de rotuladores que classificaram o tweet como linguagem ofensiva.\n",
    "\n",
    "neither: Número de rotuladores que consideraram que o tweet não se enquadra em nenhuma das categorias anteriores.\n",
    "\n",
    "class: Categoria final atribuída ao tweet, onde 0 pode representar 'hate_speech', 1 pode representar 'offensive_language', e 2 pode representar 'neither'.\n",
    "\n",
    "tweet: O conteúdo textual do tweet.\n",
    "\n",
    "\n",
    "# Descrição Estatística:\n",
    "\n",
    "\n",
    "A segunda tabela é um resumo estatístico do DataFrame com as seguintes métricas para cada coluna numérica:\n",
    "\n",
    "count: Total de registros para cada coluna.\n",
    "\n",
    "mean: Média dos valores.\n",
    "\n",
    "std (desvio padrão): Mede a quantidade de variação ou dispersão dos valores.\n",
    "\n",
    "min: Valor mínimo encontrado.\n",
    "25% (primeiro quartil): Abaixo deste valor estão os 25% menores valores.\n",
    "50% (mediana): Metade dos valores são menores que esse valor.\n",
    "75% (terceiro quartil): Abaixo deste valor estão os 75% menores valores.\n",
    "\n",
    "max: Valor máximo encontrado.\n",
    "\n",
    "\n",
    "Análise dos Dados Estatísticos:\n",
    "*\n",
    "count (count): 24,783 tweets foram rotulados, o que indica um conjunto de dados relativamente grande.\n",
    "\n",
    "hate_speech (mean): Em média, 0.28 rotuladores por tweet consideram um tweet como discurso de ódio, o que sugere que a maioria dos tweets não é considerada como tal.\n",
    "\n",
    "offensive_language (mean): Em média, 2.41 rotuladores por tweet consideram um tweet como linguagem ofensiva, indicando que é mais comum encontrar linguagem ofensiva do que discurso de ódio.\n",
    "\n",
    "neither (mean): Em média, 0.55 rotuladores por tweet não encontraram nem discurso de ódio nem linguagem ofensiva nos tweets.\n",
    "\n",
    "class (mean): A média próxima de 1.11 para a categoria final sugere que a maioria dos tweets está sendo classificada como linguagem ofensiva (1), com alguns classificados como nem ofensivos nem discurso de ódio (2).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df0bb8",
   "metadata": {
    "papermill": {
     "duration": 0.006729,
     "end_time": "2024-05-06T20:12:51.029461",
     "exception": false,
     "start_time": "2024-05-06T20:12:51.022732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Pré-processamento de Dados\n",
    "> Aplicamos funções de limpeza no texto dos tweets para remover elementos indesejados como URLs, tags HTML e caracteres especiais. Além disso, convertemos todo o texto para minúsculas para uniformizar a entrada antes da tokenização e vetorização. Este passo é essencial para preparar os dados para a modelagem efetiva.\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fe67ef",
   "metadata": {
    "papermill": {
     "duration": 3.219757,
     "end_time": "2024-05-06T20:12:54.256262",
     "exception": false,
     "start_time": "2024-05-06T20:12:51.036505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Pré-processamento de Dados\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['tweet'].apply(clean_text)  # Ajustar nome da coluna conforme necessário\n",
    "df['tokens'] = df['clean_text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e19def",
   "metadata": {
    "papermill": {
     "duration": 0.006611,
     "end_time": "2024-05-06T20:12:54.269960",
     "exception": false,
     "start_time": "2024-05-06T20:12:54.263349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Vetorização dos Dados\n",
    "> Convertendo o texto limpo em uma forma numérica usando o TF-IDF Vectorizer. A vetorização é crucial para transformar dados textuais em um formato que modelos de machine learning possam interpretar e usar para fazer previsões.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767596d",
   "metadata": {
    "papermill": {
     "duration": 0.33214,
     "end_time": "2024-05-06T20:12:54.609017",
     "exception": false,
     "start_time": "2024-05-06T20:12:54.276877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6. Vetorização dos Dados\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False, min_df=2)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1567df1",
   "metadata": {
    "papermill": {
     "duration": 2.673372,
     "end_time": "2024-05-06T20:12:57.289486",
     "exception": false,
     "start_time": "2024-05-06T20:12:54.616114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instanciar o objeto SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "# Aplicar o SMOTE ao conjunto de dados\n",
    "X_smote, y_smote = smote.fit_resample(tfidf_matrix, df['class'])\n",
    "\n",
    "# Verificar a nova distribuição das classes\n",
    "print(\"Distribuição das classes após o SMOTE:\", np.bincount(y_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91684825",
   "metadata": {
    "papermill": {
     "duration": 0.006735,
     "end_time": "2024-05-06T20:12:57.303505",
     "exception": false,
     "start_time": "2024-05-06T20:12:57.296770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Modelagem\n",
    "> Construímos e treinamos o modelo de classificação usando uma rede neural simples com TensorFlow/Keras. A arquitetura da rede é definida com camadas densas e dropout para evitar overfitting. O modelo é compilado com a função de perda `binary_crossentropy` e o otimizador `adam`, que são adequados para problemas de classificação binária.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1341bffc",
   "metadata": {
    "papermill": {
     "duration": 164.677809,
     "end_time": "2024-05-06T20:15:41.988293",
     "exception": false,
     "start_time": "2024-05-06T20:12:57.310484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construção do Modelo com Dropout para evitar overfitting\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_dim=X_smote.shape[1]),\n",
    "    tf.keras.layers.Dropout(0.5),  # Dropout adicionado após a primeira camada densa\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),  # Dropout adicionado após a segunda camada densa\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # Usar softmax para multi-classificação\n",
    "])\n",
    "    \n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99758949",
   "metadata": {
    "papermill": {
     "duration": 1.46492,
     "end_time": "2024-05-06T20:15:43.630815",
     "exception": false,
     "start_time": "2024-05-06T20:15:42.165895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convertendo probabilidades para rótulos de classe\n",
    "\n",
    "# Avaliar o modelo usando os rótulos de classe\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_classes))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33151c75",
   "metadata": {
    "papermill": {
     "duration": 0.178998,
     "end_time": "2024-05-06T20:15:43.989185",
     "exception": false,
     "start_time": "2024-05-06T20:15:43.810187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Avaliação do Modelo ( Validação)\n",
    "Avaliamos o desempenho do modelo usando o conjunto de teste, calculando métricas como acurácia e gerando um relatório de classificação. Isso nos permite ver como o modelo performa em dados não vistos e avaliar métricas importantes como precisão, recall e F1-score para cada classe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c2cce",
   "metadata": {
    "papermill": {
     "duration": 0.177573,
     "end_time": "2024-05-06T20:15:44.345973",
     "exception": false,
     "start_time": "2024-05-06T20:15:44.168400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a475b07e",
   "metadata": {
    "papermill": {
     "duration": 0.181766,
     "end_time": "2024-05-06T20:15:44.709033",
     "exception": false,
     "start_time": "2024-05-06T20:15:44.527267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # Classification Report (Relatório de Classificação):\n",
    " \n",
    " \n",
    " O relatório de classificação fornece mais detalhes sobre o desempenho do modelo em cada classe individualmente, usando métricas como precisão, recall e F1-score.\n",
    "\n",
    "Classes:\n",
    "0: Representa uma classe (possivelmente discurso de ódio).\n",
    "1: Representa outra classe (possivelmente linguagem ofensiva).\n",
    "2: Representa uma terceira classe (possivelmente linguagem neutra).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55112eb1",
   "metadata": {
    "papermill": {
     "duration": 0.181403,
     "end_time": "2024-05-06T20:15:45.074170",
     "exception": false,
     "start_time": "2024-05-06T20:15:44.892767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "## Visualizações de Resultados\n",
    "> Plotamos a curva de aprendizado e a matriz de confusão. Estas visualizações ajudam a entender como o modelo aprendeu ao longo das épocas (curva de aprendizado) e como ele performa em relação a diferentes classes (matriz de confusão).\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f030d",
   "metadata": {
    "papermill": {
     "duration": 1.900455,
     "end_time": "2024-05-06T20:15:47.156003",
     "exception": false,
     "start_time": "2024-05-06T20:15:45.255548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ajuste em y_pred para converter de probabilidades para rótulos de classe\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Converte probabilidades em rótulos de classe\n",
    "\n",
    "# Plotar a curva de aprendizado\n",
    "plot_learning_curve(history)\n",
    "\n",
    "# Plotar a matriz de confusão\n",
    "plot_classification_report(y_test, y_pred_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc70bd",
   "metadata": {
    "papermill": {
     "duration": 0.241198,
     "end_time": "2024-05-06T20:15:47.580108",
     "exception": false,
     "start_time": "2024-05-06T20:15:47.338910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Detalhes do Gráfico\n",
    "\n",
    "> Eixo X (Épocas): Mostra o número de épocas durante o treinamento do modelo. Uma época completa ocorre quando o algoritmo de aprendizado passou por todo o conjunto de dados de treinamento uma vez. Este gráfico vai de 0 a pouco mais de 17.5 épocas.\n",
    "\n",
    "\n",
    "> Eixo Y (Acurácia): Representa a acurácia do modelo, variando de 0.84 (84%) a 1.00 (100%).\n",
    "\n",
    "\n",
    "# Linhas no Gráfico\n",
    "\n",
    "> Azul (Acurácia - Dados de Treinamento): Representa a acurácia do modelo nos dados de treinamento ao longo das épocas.\n",
    "\n",
    "> Laranja (Acurácia - Dados de Validação): Representa a acurácia do modelo nos dados de validação ao longo das épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd2486",
   "metadata": {
    "papermill": {
     "duration": 0.184135,
     "end_time": "2024-05-06T20:15:47.944365",
     "exception": false,
     "start_time": "2024-05-06T20:15:47.760230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Análise\n",
    "\n",
    "1. Comportamento Inicial (Até cerca de 2.5 Épocas):\n",
    "    * Acurácia nos Dados de Treinamento: Inicia em torno de 86% e rapidamente sobe para próximo de 100%.\n",
    "    * Acurácia nos Dados de Validação: Começa mais baixo que a acurácia de treinamento, em torno de 90%, mas aumenta rapidamente para alinhar-se mais de perto com a acurácia de treinamento.\n",
    "\n",
    "\n",
    "2. Comportamento Após Aproximadamente 2.5 Épocas:\n",
    "    * Estabilização: Ambas as linhas se estabilizam, indicando que o modelo atinge um ponto de equilíbrio em sua capacidade de generalização.\n",
    "    * Acurácia nos Dados de Treinamento: Estabiliza-se muito perto de 100%, indicando que o modelo aprendeu muito bem os dados de treinamento.\n",
    "    * Acurácia nos Dados de Validação: Estabiliza-se em torno de 98%, mostrando um bom desempenho também nos dados de validação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d6d772",
   "metadata": {
    "papermill": {
     "duration": 0.184344,
     "end_time": "2024-05-06T20:15:48.313087",
     "exception": false,
     "start_time": "2024-05-06T20:15:48.128743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Layout da Matriz\n",
    "\n",
    "****Eixos:\n",
    "O eixo vertical (Y) representa as classes reais dos dados (True label).\n",
    "O eixo horizontal (X) representa as classes previstas pelo modelo (Predicted label).****\n",
    "\n",
    "****Células:\n",
    "Cada célula na matriz mostra o número de previsões para uma combinação de classe prevista e classe real.****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c1e916",
   "metadata": {
    "papermill": {
     "duration": 0.184826,
     "end_time": "2024-05-06T20:15:48.682076",
     "exception": false,
     "start_time": "2024-05-06T20:15:48.497250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Valores na Matriz:\n",
    "\n",
    "* [0,0] 3829: O modelo previu corretamente 3829 instâncias como classe 0. Estas são verdadeiros positivos para a classe 0.\n",
    "\n",
    "* [0,1] 0: O modelo não previu incorretamente nenhuma instância da classe 0 como classe 1.\n",
    "\n",
    "* [0,2] 20: O modelo previu incorretamente 20 instâncias da classe 0 como classe 2.\n",
    "\n",
    "* [1,0] 144: O modelo previu incorretamente 144 instâncias da classe 1 como classe 0.\n",
    "\n",
    "* [1,1] 3498: O modelo previu corretamente 3498 instâncias como classe 1. Estas são verdadeiros positivos para a classe 1.\n",
    "\n",
    "* [1,2] 152: O modelo previu incorretamente 152 instâncias da classe 1 como classe 2.\n",
    "\n",
    "* [2,0] 1: O modelo previu incorretamente 1 instância da classe 2 como classe 0.\n",
    "\n",
    "* [2,1] 18: O modelo previu incorretamente 18 instâncias da classe 2 como classe 1.\n",
    "\n",
    "* [2,2] 3852: O modelo previu corretamente 3852 instâncias como classe 2. Estas são verdadeiros positivos para a classe 2.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06612d05",
   "metadata": {
    "papermill": {
     "duration": 0.183493,
     "end_time": "2024-05-06T20:15:49.046871",
     "exception": false,
     "start_time": "2024-05-06T20:15:48.863378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Interpretações e Implicações\n",
    "\n",
    "> Diagonal Principal: Os números ao longo da diagonal principal (3829, 3498, 3852) representam as quantidades de previsões corretas para cada classe. Estes são seus verdadeiros positivos.\n",
    "\n",
    "> Fora da Diagonal Principal: Todos os outros números representam erros de classificação. Por exemplo, os 144 na célula [1,0] representam os falsos negativos para a classe 0 e falsos positivos para a classe 1.\n",
    "\n",
    "\n",
    "\n",
    "# Avaliação\n",
    "\n",
    "> Desempenho por Classe: O modelo parece ser bastante eficaz em identificar corretamente as classes 0 e 2, com um número significativo de verdadeiros positivos e poucos falsos positivos e falsos negativos. A classe 1 também é bem identificada, mas com mais falsos positivos e negativos comparativamente.\n",
    "\n",
    "\n",
    "> Possíveis Problemas: As pequenas quantidades de erros entre as classes 1 e 2 podem indicar confusão entre estas categorias pelo modelo, o que poderia ser um ponto de interesse para investigação ou ajuste adicional no modelo."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 723100,
     "sourceId": 1257215,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 220.179402,
   "end_time": "2024-05-06T20:15:50.957415",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-06T20:12:10.778013",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
